# mem mgmt

## toc

- addr binding
- addr spaces
- swapping
- contiguous mem allocations
- fragmentations (external & internal)
- paging
- hardware support for paging

### mem is an important resource that must be managed carefully

- mem capacities have been increasing, but programs are getting bigger faster
- parkinson's law
  - programs expand to fill mem available to hold them

### what every programmer would like

- mem with these characteristics
  - private, infinitely large, infinitely fast
  - non-volatile
  - inexpensive
- as of now, there is no such mem

### mem hierarchy

- volatile
  - registers
  - cache
  - main mem
  - electronic disk
- non-volatile
  - magnetic disk
  - optical disk
  - magnetic tapes

## mem mgmt

### why?

- main objective of system is to execute programs
- programs & data must be in mem (at least partially) during execution
- to improve cpu utilization & response times
  - several procs need to be mem resident
  - mem needs to be shared

### mem

- large array of words (bytes)
  - each word has its own addr
- typical program execution cycle
  1. fetch instruction from mem where program is stored
  2. decode
  3. execute. operands may be fetched from mem
  4. result of execution may be stored back to mem

### why procs must be mem resident

- storage that cpu can access directly
  1. registers in cpu
  2. main mem
- machine instructions take mem addrs as arguments
  - none operate on disk addrs
- any instructions in execution plus needed data must be in mem

### overheads in direct access storage devices

- cpus can decode instructions & perform simple operations on register contents - 1+ per clock cycle
- registers accessible in 1 clock cycle
- main mem access is a transaction on mem bus - takes several cycles to complete

### coping with speed differential (hardware)

- introduce fast mem between cpu & main mem for reused data
  - cache (data)
  - cache (instructions)
  - cache (translation)
  - cache (& al.)

### we must also perform correct operation (software)

- os must be protected from accesses by user procs
- user procs must be protected from eachother

### protection: making sure each proc has separate mem spaces

- determine range of legal addrs for proc
- ensure proc can access only those

### providing protection with registers

- base - smallest legal physical addr
- limit - size of range of physical addrs
- e.g. base = 300040, limit = 120900
  - legal: 300040 <--> (300040 + 120900 - 1) = 420939

### base & limit registers loaded only by os

- privileged instructions needed to load registers - executed only in kernel mode
- user programs cannot change contents of these registers
- os given unrestricted access to os & user's mem

### procs & mem

- to execute, a program needs to be placed inside a proc
- proc executes
  - access instructions & data from mem
- proc terminates
  - mem reclaimed & declared available

### binding is a mapping from 1 addr space to the next

- procs can reside in any part of physical mem
  - 1st addr of proc need not be `x0000` (duh)
- addrs in source program are symbolic
- compiler binds symbolic addrs to relocatable addrs
- loader binds relocatable addrs to absolute addrs

### binding can be done at different times

- compile time
  - known that proc will reside at location R
    - if location changes, recompile
  - ms-dos.com programs were bound this way
- load time
  - based on compiler-generated relocatable code
- execution time
  - proc can be moved around during execution
    - binding delayed until runtime
    - special hardware neededd
    - supported by most os

## addr spaces

### addr spaces

- logical
  - addrs generated by program running on cpu
- physical
  - addrs seen by mem unit
- logical addr space - set of logical addrs generated by program
- physical addr space - set of physical addrs corresponding to logical addr space

### mem mgmt unit

- mapping converts logical to physical addrs
- user program never sees real physical addr
  - create pointer to location
  - store in mem, manipulate & compare
- when used as mem addr (load/store)
  - relocated to physical mem

### generation of physical & logical addrs

- compile time & load time
  - identical logical & physical addrs
- execution time
  - logical addrs differ from physical addrs
  - logical addr referred to as virt addr
- runtime mapping performed in hardware via mem mgmt unit (mmu)

#### but do we need to load entire program in mem?

- no. only what we need to execute

### in dynamic loading, an unused routine is never loaded into mem

- routine not loaded until called
  - kept on disk in relocatable load format
- when routine calls another one
  - if routine not present, load it & update addr tables
- does not require special support from os
  - design programs appropriately

### contrasting loading & linking

- loading - load executable into mem prior to execution
- linking - takes some smaller executables & joins them together as a single larger executable

### static linking

- language libs treated as other modules
  - combined by loader into program image
- each program includes a copy of lib functions called in executable image
  - wastes disk/mem space, but makes binary self-contained

### dynamic linking

- similar to dynamic loading
- stub included for each lib reference
  - locate mem resident routine
  - how to load routine if not in mem
- after routine loaded, stub replaces itself with addr of routine
  - subsequent accesses to code segment do not incur dynamic linking costs

### unlike dynamic loading, dynamic linking needs os support

- only os can allow multiple procs to access same mem region
  - shared pages

## swapping

### swapping & mem space restrictions: effects of binding

- proc may/may not be swapped back into same space that it occupied
- binding at compile/load time - difficult to relocate
- execution time binding
  - proc can be swapped into different mem spaces
  - physical addrs computed at runtime

### when cpu scheduler decies to execute a proc, it calls dispatcher

- check whether next proc is in mem
- if next proc not in mem & no free mem
  - swap out a proc that is mem resident
  - swap in desired proc

### overheads in swapping: context switch time

- user proc size: 100MB
- transfer rate: 50MB/s
- transfer time: 2s
- avg latency: 8ms
- swap out = transfer time + latency = 2008ms
- total swap time = swap in + swap out = 4016ms

### factors constraining swapping besides swap time

- proc must be completely idle
  - no pending i/o
- device is busy so i/o is queued
  - swap out P~1~ & swap in P~2~
  - i/o operation may attempt to use P~2~'s mem
    - solution 1: never swap proc with pending i/o
    - solution 2: execute i/o operations into os buffers

### swapping not a reasonable mem mgmt solution

- too much swapping time, too little execution time
- modification of swapping exists in many versions of unix
  - swapping normally disabled
  - starts if many procs are running & set threshold is breached
  - halted when system load reduces

## contiguous mem allocation

- each proc contained in a single continuous setion of mem

### partitioning of mem

- main mem needs to accomodate os & user proc
- divided into 2 partitions
  - resident os (usually low)
  - user procs

### mem mapping & protection

- relocation register - smallest physical addr
- limit register - range of logical addrs
- when cpu scheduler selects a proc for execution
  - relocation & limit registers reloaded as part of context switch
- every addr generated by cpu checked against relocation/limit registers

### mem allocation: fixed partition method

- divide mem into several fixed size partitions
  - each partition contains exactly 1 proc
- degree of multiprogramming bound by num partitions

### mem allocation: variable partition method

- used in batch environments
- os maintains table tracking mem utilization
  - what is available?
  - which ones are occupied?
- initially all mem available
  - considered large mem hole
  - eventually many mem holes will exist
- os orders procs according to scheduling algorithm
- mem allocated to procs until requirements of next proc cannot be met
  - wait until larger block available
  - check if smaller requirements of other procs can be met
- reclaiming spaces
  - when proc arrives if space too large, split into 2
  - when proc terminates
    - if released mem adjacent to other mem holes, fuse to form larger space

### splitting & fusing mem spaces

- scenario: p3 -> split -> p4 -> split -> p1 -> bigger split -> p2

### dynamic storage allocation problem

- satisfying request of size n from set of available spaces
  - 1st fit
  - best fit
  - worst fit

### 1st fit

- scan list of segments until you find a mem gap that is big enough
- gap broken up into 2 pieces
  - 1 for proc
  - other unused

### best fit

- scan entire list beginning -> end
- pick smallest mem gap adequate to host proc

### comparing best & 1st fit

- best fit slower than 1st fit
- surprisingly, best fit also results in more wasted mem than 1st fit
  - tends to fill up mem with tiny, useless gaps

### worst fit

- always take largest available mem gap (perhaps, new gap would be useful)
- simulations have shown worst fit also not good idea

## segmentation

### base & limits translation lacks many features needed to suport modern programs

- base & limits translation supports only coarse-grained protection at level of entire proc
  - e.g. not possible to prevent program from overwriting its own code
  - also difficult to share regions of mem between 2 procs
  - since mem for proc needs to be contiguous
    - supporting dynamic mem regions for heaps, thread stacks, or mem-mapped files becomes difficult to impossible

### in our discussions so far

- logical/vram is 1d
  - logical addrs go from 0 to some max val
- many problems can benefit from having 2+ separate logical addr spaces

### a compiler has many tables that are built up as compilation proceeds

- grows continuously as compilation proceeds
  - source text
  - symbol table
    - names & attrs of vars
  - consts table
    - const int, float
  - parse tree
    - syntactic analysis of program
- grows & shrinks in unpredictable ways during compilation
  - stack
    - procedure calls within compiler

### 1d access with growing tables

- program has exceptional num vars
  - in every table, there is an amount of addr space being used, as well as a free section
- hierarchy of addr space
  - symbol table -> source text -> const table -> parse tree -> call stack

### options available to compiler

- say that compilation cannot continue (not cool)
- play robin hood
  - take space from tables with room
  - give to tables with little room

### what would be really cool

- free programmer from having to manage expansion & contraction of tables
- how?
  - provide many completely independent addr spaces (segments)
  - each segment has linear sequence of addrs (0 to max)

### segments & base/limit registers

- hardware supports array of pairs & base & bounds registers for each proc (segment table)
- each entry in array controls a segment of virt addr space
- physical mem for each segment stored contiguously, but different segments can be stored at different locations
  - e.g. code & data segments are not immediately adjacent to each other in either virt or physical addr space

### other things about segments

- different segments can & do have different lengths
- segments grow & shrink independently without affecting each other
  - e.g. consider a segment for stack
    - size increase: sth pushed onto stack segment
    - size decrease: sth popped off stack segment

#### segmentation allows users to view mem as a collection of variable-sized segments

### segmentation

- logical addr space is a collection of segments
- segments have name & length
- addrs specify segment name & offset within segment

### segmentation addring example

- 1400-2400 - segment 0
- 3200-4300 - segment 3
- 4300-4700 - segment 2
- 4800-5800 - segment 4
- 6300-6700 - segment 1

### segmentation hardware

- essentially makes sure that length calculated does not exceed length of physical addr

## fragmentation

### contiguous mem allocation: fragmentation

- as procs & segments are loaded/removed from mem, free mem space broken into small pieces
- external fragmetntation
  - enough space to satisfy request, but available spaces not contiguous

### fragmentation example

- same scenario as before: p3 -> split -> p4 -> split -> p1 -> bigger split -> p2
  - p5 is new segment but cannot be loaded because mem space fragmented

### fragmentation can be internal as well

- mem allocated to proc may be slightly larger than requested
- internal fragmentation - unused mem internal to blocks

### compaction

- solution to external fragmentation
- shuffle mem components
  - objective: place free mem in large block
- not possible if relocation static
  - load time
- approach involves moving procs towards 1 end, gaps towards other

### compaction example

- same scenario as before: p3 -> split -> p4 -> split -> p1 -> bigger split -> p2
  - p5 is new segment but cannot be loaded because mem space fragmented
  - compaction will shift all sections to beginning & allocate more than enough space for p5

### mem compaction time intensive, usually not done

- machine w 1gb ram
- can copy 4 bytes in 20 ns
- time to compact all mem = 10^9 _ (20 _ 10^-9) / 4 = 5s (approx)

## paging: overview of mapping

### overview of how mapping of logical & physical addrs performed

- cpu sends virt addr to mmu
- mmu confers with translation lookaside buffer (tlb)
- mmu may access physical mem to perform translations (pagetable may be stored there)
- mmu sends out physical addr once negotiating finished

### paging mem mgmt scheme

- physical addr space of proc can be non-contiguous
- solves problem of fitting variable-sized mem chunks to backing store
  - backing store has fragmentation problem - compaction impossible

### basic method for implementing paging

- break mem into fixed-size blocks
  - physical mem: frames
  - logical mem: pages
  - blocks are same size
- backing store also divided same way

### cool/odd things about paging

- while a program thinks of its mem as linear, it is usually scattered throughout physical mem
- processor will execute instructions piecemeal using virt addrs
  - virt addrs still linear
  - however, instruction located at end of a page will be located in a completely different region of physical mem from next instruction at start of another page
- data structures appear to be contiguous using virtual addrs, but a large matrix is scattered across many physical page frames

### paging: analogy

- shuffling several decks of cards together
- each proc in its virt addr space sees cards of its own single deck in order
- in physical mem, however, decks of all procs currently running will be shuffled together apparently at random
- page tables are magician's assistant in locating cards from shuffled decks

### paging: logical & physical mem

- logical mem: page 0-3
- page table: { 1, 4, 3, 7 }
- physical mem: { nil, 0, nil, 2, 1, nil, nil, 3 }

### paging: performing addr translation

- cpu reads logical addr (pair of page number & page offset), looks at the page
- cpu finds f & assembles physical addr with page offset, then finds the frame & reads at offset provided
